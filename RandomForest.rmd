---
output=github_document
---

# Lucas de Paula
# Assignment 3 - Random Forest

&nbsp;

```{r ,warning=FALSE,message=FALSE}

library(tidyverse)
library(tidymodels)
library(caret)
library(gridExtra)
library(vip)
library(ranger)
library(skimr)

```

&nbsp;

```{r include = FALSE}

drug = read.csv("data/drug_data.csv")

names(drug) = c("ID", "Age", "Gender", "Education", "Country", "Ethnicity","Nscore", "Escore", "Oscore", "Ascore", "Cscore", "Impulsive","SS", "Alcohol", "Amphet", "Amyl", "Benzos", "Caff", "Cannabis","Choc", "Coke", "Crack", "Ecstasy", "Heroin", "Ketamine", "Legalh","LSD", "Meth", "Mushrooms", "Nicotine", "Semer", "VSA")

str(drug)

```

&nbsp;

```{r include = FALSE}


drug[drug == "CL0"] = "No"
drug[drug == "CL1"] = "No"
drug[drug == "CL2"] = "Yes"
drug[drug == "CL3"] = "Yes"
drug[drug == "CL4"] = "Yes"
drug[drug == "CL5"] = "Yes"
drug[drug == "CL6"] = "Yes"

drug_clean = drug %>% 
  mutate_at(vars(Age:Ethnicity), funs(as_factor)) %>%
  mutate(Age = factor(Age, labels = c("18_24", "25_34", "35_44","45_54", "55_64", "65_"))) %>%
  mutate(Gender = factor(Gender, labels = c("Male", "Female"))) %>%
  mutate(Education = factor(Education, labels =c("Under16", "At16", "At17", "At18", "SomeCollege","ProfessionalCert", "Bachelors", "Masters", "Doctorate"))) %>%
  mutate(Country = factor(Country,labels = c("USA", "NewZealand", "Other", "Australia","Ireland","Canada","UK"))) %>%
  mutate(Ethnicity = factor(Ethnicity,labels = c("Black", "Asian", "White", "White/Black", "Other","White/Asian", "Black/Asian"))) %>%
  mutate_at(vars(Alcohol:VSA), funs(as_factor)) %>%
  select(-ID)

str(drug_clean)


```

```{r include = FALSE} 

drug_clean = drug_clean %>% 
  select(!(Alcohol:Mushrooms)) %>% 
  select(!(Semer:VSA))

names(drug_clean)

```

&nbsp;

## Task 1: Check for missing data in our “drug_clean” dataframe. Is there any missingness? If so, identify and implement a reasonable strategy to deal with the missingness.

&nbsp;

```{r}

skim(drug_clean)

```

&nbsp;

There is no missing data on our dataset

&nbsp;

## Task 2: Split the dataset into training (70%) and testing (30%) sets. Use a set.seed of 1234. Stratify by the “Nicotine” variable.

&nbsp;

```{r}

set.seed(1233) 
drug_split = initial_split(drug_clean, prop = 0.7, strata = Nicotine)
train = training(drug_split)
test = testing(drug_split)

```

&nbsp;

## Task 3: Create appropriate visualizations (12 in all) to examine the relationships between each variable and “Nicotine”. Use grid.arrange (from the gridExtra package) to organize these visuals (perhaps in groups of four visualizations?). Comment on the relationship between each variable and “Nicotine”.

&nbsp;

```{r}

p1 = ggplot(train, aes(x = Age, fill = Nicotine)) + geom_bar(position = "fill")
p2 = ggplot(train, aes(x = Gender, fill = Nicotine)) + geom_bar(position = "fill")
p3 = ggplot(train, aes(x = Education, fill = Nicotine)) + geom_bar(position = "fill")
p4 = ggplot(train, aes(x = Country, fill = Nicotine)) + geom_bar(position = "fill")
p5 = ggplot(train, aes(x = Ethnicity, fill = Nicotine)) + geom_bar(position = "fill")
grid.arrange(p1,p2,p3,p4, p5)

```

&nbsp;

Between the categorical variables, there seems to be a strong correlation between Age and Nocotine consume - as the age increases, nicotine usage decreases. There seems to be less nitotine consume in black and asian communities compared to other ethnicities. and it seems that males consume more nicotine than women. 

&nbsp;

```{r}

p1 = ggplot(train, aes(x = Nicotine, y = Nscore)) + geom_boxplot()
p2 = ggplot(train, aes(x = Nicotine, y = Escore)) + geom_boxplot()
p3 = ggplot(train, aes(x = Nicotine, y = Oscore)) + geom_boxplot()
p4 = ggplot(train, aes(x = Nicotine, y = Ascore)) + geom_boxplot()
grid.arrange(p1,p2,p3,p4)

```

&nbsp;

```{r}

p1 = ggplot(train, aes(x = Nicotine, y = Cscore)) + geom_boxplot()
p2 = ggplot(train, aes(x = Nicotine, y = Impulsive)) + geom_boxplot()
p3 = ggplot(train, aes(x = Nicotine, y = SS)) + geom_boxplot()
grid.arrange(p1,p2,p3, ncol = 2)

```

&nbsp;

When it comes to numerical variables, there isn't much to be seen when comparing them against Nitocine. Maybe the most expressive difference is in the SS (sensation seeking) variable  - where it is higher, on average, for those that consume nicotine than for those that don't.

&nbsp;

## Task 4: Create a random forest model on the training set to predict Nicotine using all of the variables in thedataset. You 5-fold, k-fold cross-validation (random number seed of 123 for the folds). Allow R to select mtry values between 2 and 8 and min_n values between 5 and 20. Use 10 levels in your “grid_regular” function.Set a random number seed of 123 for the tune_grid function. Use 100 trees.Visualize the relationships between parameters and performance metrics.

&nbsp;

```{r}

set.seed(123)
rf_folds = vfold_cv(train, v = 5)

drug_recipe = recipe(Nicotine ~., train) %>%
  step_dummy(all_nominal(), -all_outcomes())

rf_model = rand_forest(mtry = tune() , min_n = tune(), trees = 100) %>% 
  set_engine("ranger", importance = "permutation") %>% 
  set_mode("classification")

drug_wflow = 
  workflow() %>% 
  add_model(rf_model) %>% 
  add_recipe(drug_recipe)

rf_grid = grid_regular(
  mtry(range = c(2, 8)), 
  min_n(range = c(5, 20)),
  levels = 10
)

set.seed(123)
rf_res_tuned = tune_grid(
  drug_wflow,
  resamples = rf_folds,
  grid = rf_grid
)

```

&nbsp;

```{r}
rf_res_tuned %>%
  collect_metrics() %>%
  filter(.metric == "accuracy") %>%
  select(mean, min_n, mtry) %>%
  pivot_longer(min_n:mtry,
    values_to = "value",
    names_to = "parameter"
  ) %>%
  ggplot(aes(value, mean, color = parameter)) +
  geom_point(show.legend = FALSE) +
  facet_wrap(~parameter, scales = "free_x") +
  labs(x = NULL, y = "Accuracy")
```

&nbsp;

## Task 5: Use the best mtry and min_n values from Task 4 to finalize the workflow and fit the model to training set. Examine variable importance. What variables are most important in this model? (Hint: Referback to the dataset’s webpage if you need clarification as to meaning of any variables).

&nbsp;

```{r}

best_rf = select_best(rf_res_tuned, "accuracy")

final_rf = finalize_workflow(
  drug_wflow,
  best_rf
)

final_rf

```

&nbsp;

```{r}
final_rf_fit = fit(final_rf, train)

final_rf_fit %>% pull_workflow_fit() %>% vip(geom = "point")
```

&nbsp;

The most important varables on the dataset are: SS (sensation seeking), Cscore (Conscientiousness), Country UK and Oscore (Openness to experience).

&nbsp;

## Task 6: How does the model perform on the training and testing sets?

&nbsp;

```{r}

# Training

trainpredrf = predict(final_rf_fit, train)
head(trainpredrf)

confusionMatrix(trainpredrf$.pred_class, train$Nicotine, 
                positive = "Yes")

```

&nbsp;

```{r}
# Testing

testpredrf = predict(final_rf_fit, test)
head(testpredrf)

confusionMatrix(testpredrf$.pred_class, test$Nicotine, 
                positive = "Yes")
```

&nbsp;

The model has an accuracy of 0.9188 on the training dataset and 0.7143 on the testing dataset - which is a big difference in performance. This model is not good at generalizing. I think a hint that the model is not good is to compare the variable importance graph against the initial exploration we had done. The variables we thought were going to impact the model performance were not used in the model. One thing we could do to try to improve the model is to add those variables to the model by forcing it. 

&nbsp;

## Task 7: Comment on how this model might be used in the “real-world.” Would you recommend this modelfor real-world use? What if any concerns would you have about using the model?

&nbsp;

This model could be used to have a high level understanding of the factors that might lead someone to try nicotine or become a user. Our model, as it selected fewer variables, doesn't generalize well and could potentially be better if we kept different variables such as other types of drugs. That could help us understand if a more serious problem could arise in society due to the fact that someone has an inclination to move towards other drugs.
I would not use this model to make specific recommendations or deny/allow service to a person as the accuracy and other metrics of the model make me believe it is not a accurate model and relies on a few variables to make its predictions. 